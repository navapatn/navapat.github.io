---
permalink: /
title: "Welcome!"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am Navapat Nananukul or you can call me Pat. I am currently working as a student reseacher at USC Information Sciences Institute, under the advise of [Prof. Mayank Kejriwal](https://viterbi.usc.edu/directory/faculty/Kejriwal/Mayank). I am a junior researcher in the field of _Aritificial Intelligence_, I am motivated by its capacity to emulate human-like behaviors that we, as humans, train these machines. My research lies at the intersection of two complementary fields _Large Language models_ and _Knowledge Graph_, both of which are crucial for enabling machines to communicate, interact, and reason in ways that are remarkably human.

My reseach interest questions mainly include:

- Knowledge graph: How to build human intelligence structure to improve machine learning or language model.
- Application of knowledge graph to language models i.e. Question-answering, Commonsense-reasoning, etc.
- How to reduce false information, hallucination, bias in language model.



About me
======

I received my Master's degree from **USC Viterbi Department of Computer Science**. In the last semester, I was fortunate to be advised by [Prof. Mohammad Rostami](https://viterbi.usc.edu/directory/faculty/Rostami/Mohammad) who gave me the first official research experience in the CS field. We worked on improving domain adpatation, image segmentation performance for medical MRI scan images. I received my Bachelor's degree in Computer Science from Chulalongkorn University with class honor.

Research
======

Recently, I have been working on topics that allow human to understand state-of-the-art LLMs and utilize them efficeintly. Specifically, **(1) Knowledge graph ontology design for LLMs hallucination** aimed to capture hallucination we see from prompts and answers from large language model, and systemetically store into a knowledge graph structure so that we can utilize this data and potentially improve or intervene prompting processes to reduce hallucination, bias, etc. Moreover, I started working on the topic of knowledge graph building. The works include **(2) Cost-aware prompt engineering in unsupervised entity resolution** which aimed to build and gauge the performance of state-of-the-art LLMs in one of the key steps of knowledge graph building process "Entity resolution (ER)". Lastly, I am working on **(3) Blocks prioritization for unsupervised entity resolution in the era of LLMs** where we propose algorithm that bridge the gap between LLMs and entity resolution while also considering cost and maintaining great ER performance.

My ongoing research list is available in this link: [Current Research](https://navapatn.github.io/talks/)

