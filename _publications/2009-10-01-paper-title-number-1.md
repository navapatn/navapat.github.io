---
title: "How does prompt engineering affect ChatGPT performance on unsupervised entity resolution?"
collection: publications
permalink: /publication/2009-10-01-paper-title-number-1
excerpt: 'Entity Resolution (ER) is the problem of semi-automatically determining when two entities refer to the same underlying entity, with applications ranging from healthcare to e-commerce. Traditional ER solutions required considerable manual expertise, including feature engineering, as well as identification and curation of training data. In many instances, such techniques are highly dependent on the domain. With recent advent in large language models (LLMs), there is an opportunity to make ER much more seamless and domain-independent. However, it is also well known that LLMs can pose risks, and that the quality of their outputs can depend on so-called prompt engineering. Unfortunately, a systematic experimental study on the effects of different prompting methods for addressing ER, using LLMs like ChatGPT, has been lacking thus far. This paper aims to address this gap by conducting such a study. Although preliminary in nature, our results show that prompting can significantly affect the quality of ER, although it affects some metrics more than others, and can also be dataset dependent.'
date: 2023-10-01
venue: 'arXiv preprint'
paperurl: 'https://arxiv.org/abs/2310.06174'
citation: 'Nananukul, N., Sisaengsuwanchai, K., Kejriwal, M. (2023). "How does prompt engineering affect ChatGPT performance on unsupervised entity resolution?" <i>arXiv preprint arXiv:2310.06174</i>. 1(1).'
---
This paper is about the number 1. The number 2 is left for future work.

[Download paper here](https://arxiv.org/abs/2310.06174)

Recommended citation: Nananukul, N., Sisaengsuwanchai, K., Kejriwal, M. (2023). "How does prompt engineering affect ChatGPT performance on unsupervised entity resolution?" <i>Journal 1</i>. 1(1).
